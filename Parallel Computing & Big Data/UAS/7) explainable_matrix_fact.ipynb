{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MzSv49iMF1_"
      },
      "source": [
        "# Explainable Matrix Factorization (EMF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tzVT8O8-N_o"
      },
      "source": [
        "### How to quantify explainability ?\n",
        "\n",
        "- Use the rating distribution within the active user’s neighborhood. \n",
        "- If many neighbors have rated the recommended item, then this can provide a basis upon which to explain the recommendations, using neighborhood style explanation mechanisms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7rpoYzi-N_p"
      },
      "source": [
        "According to [(Abdollahi and Nasraoui, 2016)](https://www.researchgate.net/publication/301616080_Explainable_Matrix_Factorization_for_Collaborative_Filtering), an item $i$ is consider to be explainable for user $u$ if a considerable number of its neighbors rated item $i$. The explainability score $E_{ui}$ is the percentage of user $u$'s neighbors who have rated item $i$.\n",
        "\n",
        "\\begin{equation}\n",
        "E_{ui} = \\frac{|N_k^{(i)}(u)|}{|N_k(u)|},\n",
        "\\end{equation}\n",
        "\n",
        "where $N_k(u)$ is the set of $k$ nearest neighbors of user $u$ and $N_k^{(i)}(u)$ is the set of user $u$'s neighbors who have rated item $i$. However, only explainable scores above an optimal threshold $\\theta$ are accepted.\n",
        "\n",
        "\\begin{equation}\n",
        "W_{ui} = \\begin{cases} E_{ui} \\text{  } if \\text{  } E_{ui} > \\theta \\\\ 0 \\text{ } otherwise \\end{cases},\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIrA6ZKD-N_q"
      },
      "source": [
        "By including explainability weight in the training algorithm, the new objective function, to be minimized over the set of known ratings, has been formulated by [(Abdollahi and Nasraoui, 2016)](https://www.researchgate.net/publication/301616080_Explainable_Matrix_Factorization_for_Collaborative_Filtering) as:\n",
        "\n",
        "\\begin{equation}\n",
        " J = \\sum_{(u,i)\\in \\kappa} (R_{ui} - \\hat{R}_{ui})^2 +\\frac{\\beta}{2}(||P_u||^2 + ||Q_i||^2) + \\frac{\\lambda}{2}(P_u-Q_i)^2W_{ui},\n",
        "\\end{equation}\n",
        "\n",
        "here, $\\frac{\\beta}{2}(||P_u||^2 + ||Q_i||^2)$ is the $L_2$ regularization term weighted by the coefficient $\\beta$, and $\\lambda$ is an explainability regularization coefficient that controls the smoothness of the new representation and tradeoff between explainability and accuracy. The idea here is that if item $i$ is explainable for user $u$, then their representations in the latent space, $Q_i$ and $P_u$, should be close to each other. Stochastic Gradient descent can be used to optimize the objectve function.\n",
        "\n",
        "\\begin{equation}\n",
        "P_u \\leftarrow P_u + \\alpha\\left(2(R_{u,i}-P_uQ_i^{\\top})Q_i - \\beta P_u - \\lambda(P_u-Q_i)W_{ui}\\right)\n",
        "\\end{equation}\n",
        "\\begin{equation}\n",
        "Q_i \\leftarrow Q_i + \\alpha\\left(2(R_{u,i}-P_uQ_i^{\\top})P_u - \\beta Q_i + \\lambda(P_u-Q_i)W_{ui}\\right)\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4k3EF8VMF2D"
      },
      "source": [
        "## Explainable Matrix Factorization : Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s9d4Jm7n-N_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f9480a2-8186-4748-c0eb-30bd448e4d83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-03 11:40:22--  https://github.com/nzhinusoftcm/review-on-collaborative-filtering/raw/master/recsys.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/nzhinusoftcm/review-on-collaborative-filtering/master/recsys.zip [following]\n",
            "--2023-01-03 11:40:22--  https://raw.githubusercontent.com/nzhinusoftcm/review-on-collaborative-filtering/master/recsys.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15312323 (15M) [application/zip]\n",
            "Saving to: ‘recsys.zip’\n",
            "\n",
            "recsys.zip          100%[===================>]  14.60M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2023-01-03 11:40:23 (177 MB/s) - ‘recsys.zip’ saved [15312323/15312323]\n",
            "\n",
            "Archive:  recsys.zip\n",
            "   creating: recsys/\n",
            "  inflating: recsys/datasets.py      \n",
            "  inflating: recsys/preprocessing.py  \n",
            "  inflating: recsys/utils.py         \n",
            "  inflating: recsys/requirements.txt  \n",
            "   creating: recsys/.vscode/\n",
            "  inflating: recsys/.vscode/settings.json  \n",
            "   creating: recsys/__pycache__/\n",
            "  inflating: recsys/__pycache__/datasets.cpython-36.pyc  \n",
            "  inflating: recsys/__pycache__/datasets.cpython-37.pyc  \n",
            "  inflating: recsys/__pycache__/utils.cpython-36.pyc  \n",
            "  inflating: recsys/__pycache__/preprocessing.cpython-37.pyc  \n",
            "  inflating: recsys/__pycache__/datasets.cpython-38.pyc  \n",
            "  inflating: recsys/__pycache__/preprocessing.cpython-36.pyc  \n",
            "  inflating: recsys/__pycache__/preprocessing.cpython-38.pyc  \n",
            "   creating: recsys/memories/\n",
            "  inflating: recsys/memories/ItemToItem.py  \n",
            "  inflating: recsys/memories/UserToUser.py  \n",
            "   creating: recsys/memories/__pycache__/\n",
            "  inflating: recsys/memories/__pycache__/UserToUser.cpython-36.pyc  \n",
            "  inflating: recsys/memories/__pycache__/UserToUser.cpython-37.pyc  \n",
            "  inflating: recsys/memories/__pycache__/ItemToItem.cpython-37.pyc  \n",
            "  inflating: recsys/memories/__pycache__/user2user.cpython-36.pyc  \n",
            "  inflating: recsys/memories/__pycache__/ItemToItem.cpython-36.pyc  \n",
            "   creating: recsys/models/\n",
            "  inflating: recsys/models/SVD.py    \n",
            "  inflating: recsys/models/MatrixFactorization.py  \n",
            "  inflating: recsys/models/ExplainableMF.py  \n",
            "  inflating: recsys/models/NonnegativeMF.py  \n",
            "   creating: recsys/models/__pycache__/\n",
            "  inflating: recsys/models/__pycache__/SVD.cpython-36.pyc  \n",
            "  inflating: recsys/models/__pycache__/MatrixFactorization.cpython-37.pyc  \n",
            "  inflating: recsys/models/__pycache__/ExplainableMF.cpython-36.pyc  \n",
            "  inflating: recsys/models/__pycache__/ExplainableMF.cpython-37.pyc  \n",
            "  inflating: recsys/models/__pycache__/MatrixFactorization.cpython-36.pyc  \n",
            "   creating: recsys/metrics/\n",
            "  inflating: recsys/metrics/EvaluationMetrics.py  \n",
            "   creating: recsys/img/\n",
            "  inflating: recsys/img/MF-and-NNMF.png  \n",
            "  inflating: recsys/img/svd.png      \n",
            "  inflating: recsys/img/MF.png       \n",
            "   creating: recsys/predictions/\n",
            "   creating: recsys/predictions/item2item/\n",
            "   creating: recsys/weights/\n",
            "   creating: recsys/weights/item2item/\n",
            "   creating: recsys/weights/item2item/ml1m/\n",
            "  inflating: recsys/weights/item2item/ml1m/similarities.npy  \n",
            "  inflating: recsys/weights/item2item/ml1m/neighbors.npy  \n",
            "   creating: recsys/weights/item2item/ml100k/\n",
            "  inflating: recsys/weights/item2item/ml100k/similarities.npy  \n",
            "  inflating: recsys/weights/item2item/ml100k/neighbors.npy  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if not (os.path.exists(\"recsys.zip\") or os.path.exists(\"recsys\")):\n",
        "    !wget https://github.com/nzhinusoftcm/review-on-collaborative-filtering/raw/master/recsys.zip    \n",
        "    !unzip recsys.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8X07ShD-N_w"
      },
      "source": [
        "### requirements\n",
        "\n",
        "```\n",
        "matplotlib==3.2.2\n",
        "numpy==1.18.1\n",
        "pandas==1.0.5\n",
        "python==3.6.10\n",
        "scikit-learn==0.23.1\n",
        "scipy==1.5.0\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x_ohlWURMF2F"
      },
      "outputs": [],
      "source": [
        "from recsys.memories.UserToUser import UserToUser\n",
        "\n",
        "from recsys.preprocessing import mean_ratings\n",
        "from recsys.preprocessing import normalized_ratings\n",
        "from recsys.preprocessing import ids_encoder\n",
        "from recsys.preprocessing import train_test_split\n",
        "from recsys.preprocessing import rating_matrix\n",
        "from recsys.preprocessing import get_examples\n",
        "\n",
        "from recsys.datasets import ml100k, ml1m\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import sys\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HH3uJ3m-N_x"
      },
      "source": [
        "### Compute Explainable Scores\n",
        "\n",
        "Explainable score are computed using neighborhood based similarities. Here, we are using the user based algorithme to compute similarities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JBHjXG_3-N_y"
      },
      "outputs": [],
      "source": [
        "def explainable_score(user2user, users, items, theta=0):\n",
        "    \n",
        "    def _progress(count):\n",
        "        sys.stdout.write('\\rCompute Explainable score. Progress status : %.1f%%'%(float(count/len(users))*100.0))\n",
        "        sys.stdout.flush()\n",
        "    # initialize explainable score to zeros\n",
        "    W = np.zeros((len(users), len(items)))\n",
        "\n",
        "    for count, u in enumerate(users):            \n",
        "        candidate_items = user2user.find_user_candidate_items(u)        \n",
        "        for i in candidate_items:                \n",
        "            user_who_rated_i, similar_user_who_rated_i = \\\n",
        "                user2user.similar_users_who_rated_this_item(u, i)\n",
        "            if user_who_rated_i.shape[0] == 0:\n",
        "                w = 0.0\n",
        "            else:\n",
        "                w = similar_user_who_rated_i.shape[0] / user_who_rated_i.shape[0]\n",
        "            W[u,i] =  w  if w > theta else 0.0\n",
        "        _progress(count)\n",
        "    return W"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQnkpfZn-N_z"
      },
      "source": [
        "### Explainable Matrix Factorization Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zdwd9lic-N_z"
      },
      "outputs": [],
      "source": [
        "class ExplainableMatrixFactorization:\n",
        "    \n",
        "    def __init__(self, m, n, W, alpha=0.001, beta=0.01, lamb=0.1, k=10):\n",
        "        \"\"\"\n",
        "            - R : Rating matrix of shape (m,n) \n",
        "            - W : Explainability Weights of shape (m,n)\n",
        "            - k : number of latent factors\n",
        "            - beta : L2 regularization parameter\n",
        "            - lamb : explainability regularization coefficient\n",
        "            - theta : threshold above which an item is explainable for a user\n",
        "        \"\"\"\n",
        "        self.W = W\n",
        "        self.m = m\n",
        "        self.n = n\n",
        "        \n",
        "        np.random.seed(64)\n",
        "        \n",
        "        # initialize the latent factor matrices P and Q (of shapes (m,k) and (n,k) respectively) that will be learnt\n",
        "        self.k = k\n",
        "        self.P = np.random.normal(size=(self.m,k))\n",
        "        self.Q = np.random.normal(size=(self.n,k))\n",
        "        \n",
        "        # hyperparameter initialization\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.lamb = lamb\n",
        "        \n",
        "        # training history\n",
        "        self.history = {\n",
        "            \"epochs\":[],\n",
        "            \"loss\":[],\n",
        "            \"val_loss\":[],\n",
        "        }\n",
        "        \n",
        "    def print_training_parameters(self):\n",
        "        print('Training EMF')\n",
        "        print(f'k={self.k} \\t alpha={self.alpha} \\t beta={self.beta} \\t lambda={self.lamb}')\n",
        "        \n",
        "    def update_rule(self, u, i, error):\n",
        "        self.P[u] = self.P[u] + \\\n",
        "            self.alpha*(2 * error*self.Q[i] - self.beta*self.P[u] - self.lamb*(self.P[u] - self.Q[i]) * self.W[u,i])\n",
        "        \n",
        "        self.Q[i] = self.Q[i] + \\\n",
        "            self.alpha*(2 * error*self.P[u] - self.beta*self.Q[i] + self.lamb*(self.P[u] - self.Q[i]) * self.W[u,i])\n",
        "        \n",
        "    def mae(self,  x_train, y_train):\n",
        "        \"\"\"\n",
        "        returns the Mean Absolute Error\n",
        "        \"\"\"\n",
        "        # number of training exemples\n",
        "        M = x_train.shape[0]\n",
        "        error = 0\n",
        "        for pair, r in zip(x_train, y_train):\n",
        "            u, i = pair\n",
        "            error += np.absolute(r - np.dot(self.P[u], self.Q[i]))\n",
        "        return error/M\n",
        "    \n",
        "    def print_training_progress(self, epoch, epochs, error, val_error, steps=5):\n",
        "        if epoch == 1 or epoch % steps == 0 :\n",
        "                print(f\"epoch {epoch}/{epochs} - loss : {round(error,3)} - val_loss : {round(val_error,3)}\")\n",
        "                \n",
        "    def learning_rate_schedule(self, epoch, target_epochs = 20):\n",
        "        if (epoch >= target_epochs) and (epoch % target_epochs == 0):\n",
        "                factor = epoch // target_epochs\n",
        "                self.alpha = self.alpha * (1 / (factor * 20))\n",
        "                print(\"\\nLearning Rate : {}\\n\".format(self.alpha))\n",
        "        \n",
        "    def fit(self, x_train, y_train, validation_data, epochs=10):\n",
        "        \"\"\"\n",
        "        Train latent factors P and Q according to the training set\n",
        "        \n",
        "        :param\n",
        "            - x_train : training pairs (u,i) for which rating r_ui is known\n",
        "            - y_train : set of ratings r_ui for all training pairs (u,i)\n",
        "            - validation_data : tuple (x_test, y_test)\n",
        "            - epochs : number of time to loop over the entire training set. \n",
        "            10 epochs by default\n",
        "            \n",
        "        Note that u and i are encoded values of userid and itemid\n",
        "        \"\"\"\n",
        "        self.print_training_parameters()\n",
        "        \n",
        "        # get validation data\n",
        "        x_test, y_test = validation_data\n",
        "        \n",
        "        for epoch in range(1, epochs+1):\n",
        "            for pair, r in zip(x_train, y_train):                \n",
        "                u,i = pair                \n",
        "                r_hat = np.dot(self.P[u], self.Q[i])                \n",
        "                e = r - r_hat\n",
        "                self.update_rule(u, i, error=e)\n",
        "                \n",
        "            # training and validation error  after this epochs\n",
        "            error = self.mae(x_train, y_train)\n",
        "            val_error = self.mae(x_test, y_test)\n",
        "            self.update_history(epoch, error, val_error)            \n",
        "            self.print_training_progress(epoch, epochs, error, val_error, steps=1)\n",
        "        \n",
        "        return self.history\n",
        "    \n",
        "    def update_history(self, epoch, error, val_error):\n",
        "        self.history['epochs'].append(epoch)\n",
        "        self.history['loss'].append(error)\n",
        "        self.history['val_loss'].append(val_error)\n",
        "    \n",
        "    def evaluate(self, x_test, y_test):\n",
        "        \"\"\"\n",
        "        compute the global error on the test set\n",
        "        \n",
        "        :param\n",
        "            - x_test : test pairs (u,i) for which rating r_ui is known\n",
        "            - y_test : set of ratings r_ui for all test pairs (u,i)\n",
        "        \"\"\"\n",
        "        error = self.mae(x_test, y_test)\n",
        "        print(f\"validation error : {round(error,3)}\")\n",
        "      \n",
        "    def predict(self, userid, itemid):\n",
        "        \"\"\"\n",
        "        Make rating prediction for a user on an item\n",
        "\n",
        "        :param\n",
        "        - userid\n",
        "        - itemid\n",
        "\n",
        "        :return\n",
        "        - r : predicted rating\n",
        "        \"\"\"\n",
        "        # encode user and item ids to be able to access their latent factors in\n",
        "        # matrices P and Q\n",
        "        u = uencoder.transform([userid])[0]\n",
        "        i = iencoder.transform([itemid])[0]\n",
        "\n",
        "        # rating prediction using encoded ids. Dot product between P_u and Q_i\n",
        "        r = np.dot(self.P[u], self.Q[i])\n",
        "\n",
        "        return r\n",
        "\n",
        "    def recommend(self, userid, N=30):\n",
        "        \"\"\"\n",
        "        make to N recommendations for a given user\n",
        "\n",
        "        :return \n",
        "        - (top_items,preds) : top N items with the highest predictions \n",
        "        \"\"\"\n",
        "        # encode the userid\n",
        "        u = uencoder.transform([userid])[0]\n",
        "\n",
        "        # predictions for this user on all product\n",
        "        predictions = np.dot(self.P[u], self.Q.T)\n",
        "\n",
        "        # get the indices of the top N predictions\n",
        "        top_idx = np.flip(np.argsort(predictions))[:N]\n",
        "\n",
        "        # decode indices to get their corresponding itemids\n",
        "        top_items = iencoder.inverse_transform(top_idx)\n",
        "\n",
        "        # take corresponding predictions for top N indices\n",
        "        preds = predictions[top_idx]\n",
        "\n",
        "        return top_items, preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EKoHs38_-N_2"
      },
      "outputs": [],
      "source": [
        "epochs = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_OBvak6-N_3"
      },
      "source": [
        "# Model Evaluation\n",
        "\n",
        "## 1. MovieLens 100K\n",
        "\n",
        "### 1.1. Evaluation on raw data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FS5hIo0t-N_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0fe986b-2e38-4878-cb5f-436bb2218201"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download data 100.2%\n",
            "Successfully downloaded ml-100k.zip 4924029 bytes.\n",
            "Unzipping the ml-100k.zip zip file ...\n"
          ]
        }
      ],
      "source": [
        "# load data\n",
        "ratings, movies = ml100k.load()\n",
        "\n",
        "# encode users and items ids\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "users = sorted(ratings.userid.unique())\n",
        "items = sorted(ratings.itemid.unique())\n",
        "\n",
        "m = len(users)\n",
        "n = len(items)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Xzs8bGNM-N_4",
        "outputId": "288e566d-d126-436d-a894-67f75dd0b71d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalize users ratings ...\n",
            "Initialize the similarity model ...\n",
            "Compute nearest neighbors ...\n",
            "User to user recommendation model created with success ...\n",
            "Compute Explainable score. Progress status : 99.9%"
          ]
        }
      ],
      "source": [
        "# create the user to user model for similarity measure\n",
        "usertouser = UserToUser(ratings, movies)\n",
        "\n",
        "# compute explainable score\n",
        "W = explainable_score(usertouser, users, items)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9GCkuLn2-N_6",
        "outputId": "03f86fd2-8779-48c2-e9fb-568ade722a13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training EMF\n",
            "k=10 \t alpha=0.01 \t beta=0.4 \t lambda=0.01\n",
            "epoch 1/10 - loss : 0.922 - val_loss : 1.036\n",
            "epoch 2/10 - loss : 0.79 - val_loss : 0.873\n",
            "epoch 3/10 - loss : 0.766 - val_loss : 0.837\n",
            "epoch 4/10 - loss : 0.757 - val_loss : 0.822\n",
            "epoch 5/10 - loss : 0.753 - val_loss : 0.814\n",
            "epoch 6/10 - loss : 0.751 - val_loss : 0.808\n",
            "epoch 7/10 - loss : 0.749 - val_loss : 0.805\n",
            "epoch 8/10 - loss : 0.748 - val_loss : 0.802\n",
            "epoch 9/10 - loss : 0.746 - val_loss : 0.799\n",
            "epoch 10/10 - loss : 0.745 - val_loss : 0.797\n"
          ]
        }
      ],
      "source": [
        "# initialize the model\n",
        "EMF = ExplainableMatrixFactorization(m, n, W, alpha=0.01, beta=0.4, lamb=0.01, k=10)\n",
        "\n",
        "history = EMF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc6F0HWMWbLd",
        "outputId": "aab27c6c-5a9d-4fe6-c971-1c3aba39b4f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation error : 0.797\n"
          ]
        }
      ],
      "source": [
        "EMF.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhYTTRML-N_8"
      },
      "source": [
        "### 1.2. Evaluation on normalized data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nIOutckX-N_8"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "ratings, movies = ml100k.load()\n",
        "\n",
        "# encode users and items ids\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "users = sorted(ratings.userid.unique())\n",
        "items = sorted(ratings.itemid.unique())\n",
        "\n",
        "m = len(users)\n",
        "n = len(items)\n",
        "\n",
        "# normalize ratings by substracting means\n",
        "normalized_column_name = \"norm_rating\"\n",
        "ratings = normalized_ratings(ratings, norm_column=normalized_column_name)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column=normalized_column_name)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "G_JrGTXU-N_9",
        "outputId": "332c1c39-aaf8-4591-e561-fd22a79e6fa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training EMF\n",
            "k=10 \t alpha=0.022 \t beta=0.65 \t lambda=0.01\n",
            "epoch 1/10 - loss : 0.809 - val_loss : 0.842\n",
            "epoch 2/10 - loss : 0.809 - val_loss : 0.829\n",
            "epoch 3/10 - loss : 0.807 - val_loss : 0.821\n",
            "epoch 4/10 - loss : 0.799 - val_loss : 0.811\n",
            "epoch 5/10 - loss : 0.789 - val_loss : 0.8\n",
            "epoch 6/10 - loss : 0.782 - val_loss : 0.793\n",
            "epoch 7/10 - loss : 0.778 - val_loss : 0.789\n",
            "epoch 8/10 - loss : 0.776 - val_loss : 0.786\n",
            "epoch 9/10 - loss : 0.774 - val_loss : 0.784\n",
            "epoch 10/10 - loss : 0.773 - val_loss : 0.783\n"
          ]
        }
      ],
      "source": [
        "# initialize the model\n",
        "EMF = ExplainableMatrixFactorization(m, n, W, alpha=0.022, beta=0.65, lamb=0.01, k=10)\n",
        "\n",
        "history = EMF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrkhHz5J-N_-"
      },
      "source": [
        "## 2. MovieLens 1M\n",
        "\n",
        "### 2.1. Evaluation on raw data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yBTYruQs-N_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53f5052f-222a-4b13-8b81-efbaf39e9868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download data 100.1%\n",
            "Successfully downloaded ml-1m.zip 5917549 bytes.\n",
            "Unzipping the ml-1m.zip zip file ...\n"
          ]
        }
      ],
      "source": [
        "# load data\n",
        "ratings, movies = ml1m.load()\n",
        "\n",
        "# encode users and items ids\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "users = sorted(ratings.userid.unique())\n",
        "items = sorted(ratings.itemid.unique())\n",
        "\n",
        "m = len(users)\n",
        "n = len(items)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tI17ssnP-N_-",
        "outputId": "2dc4e5af-6b49-49bf-e09f-74859b74da54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalize users ratings ...\n",
            "Initialize the similarity model ...\n",
            "Compute nearest neighbors ...\n",
            "User to user recommendation model created with success ...\n",
            "Compute Explainable score. Progress status : 100.0%"
          ]
        }
      ],
      "source": [
        "# create the user to user model for similarity measure\n",
        "usertouser = UserToUser(ratings, movies)\n",
        "\n",
        "# compute explainable score\n",
        "W = explainable_score(usertouser, users, items)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wSTaGMSr-N__",
        "outputId": "625805c0-6162-41ee-c813-fa4c5197d228",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training EMF\n",
            "k=10 \t alpha=0.01 \t beta=0.4 \t lambda=0.01\n",
            "epoch 1/10 - loss : 0.782 - val_loss : 0.807\n",
            "epoch 2/10 - loss : 0.762 - val_loss : 0.781\n",
            "epoch 3/10 - loss : 0.76 - val_loss : 0.775\n",
            "epoch 4/10 - loss : 0.758 - val_loss : 0.771\n",
            "epoch 5/10 - loss : 0.757 - val_loss : 0.769\n",
            "epoch 6/10 - loss : 0.756 - val_loss : 0.767\n",
            "epoch 7/10 - loss : 0.754 - val_loss : 0.764\n",
            "epoch 8/10 - loss : 0.752 - val_loss : 0.762\n",
            "epoch 9/10 - loss : 0.751 - val_loss : 0.761\n",
            "epoch 10/10 - loss : 0.75 - val_loss : 0.76\n"
          ]
        }
      ],
      "source": [
        "# initialize the model\n",
        "EMF = ExplainableMatrixFactorization(m, n, W, alpha=0.01, beta=0.4, lamb=0.01, k=10)\n",
        "\n",
        "history = EMF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kfmPRFl-N__"
      },
      "source": [
        "### 2.2. Evaluation on normalized data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "UdtfDMS_-OAA"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "ratings, movies = ml1m.load()\n",
        "\n",
        "# encode users and items ids\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "# normalize ratings by substracting means\n",
        "normalized_column_name = \"norm_rating\"\n",
        "ratings = normalized_ratings(ratings, norm_column=normalized_column_name)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column=normalized_column_name)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DLMm1DX7-OAA",
        "outputId": "a05ee1f7-b7ac-4765-d456-0ca48dc1ac43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training EMF\n",
            "k=10 \t alpha=0.023 \t beta=0.59 \t lambda=0.01\n",
            "epoch 1/10 - loss : 0.805 - val_loss : 0.814\n",
            "epoch 2/10 - loss : 0.764 - val_loss : 0.77\n",
            "epoch 3/10 - loss : 0.756 - val_loss : 0.762\n",
            "epoch 4/10 - loss : 0.755 - val_loss : 0.759\n",
            "epoch 5/10 - loss : 0.754 - val_loss : 0.759\n",
            "epoch 6/10 - loss : 0.754 - val_loss : 0.758\n",
            "epoch 7/10 - loss : 0.754 - val_loss : 0.758\n",
            "epoch 8/10 - loss : 0.753 - val_loss : 0.758\n",
            "epoch 9/10 - loss : 0.753 - val_loss : 0.758\n",
            "epoch 10/10 - loss : 0.753 - val_loss : 0.758\n"
          ]
        }
      ],
      "source": [
        "# initialize the model\n",
        "EMF = ExplainableMatrixFactorization(m, n, W, alpha=0.023, beta=0.59, lamb=0.01, k=10)\n",
        "\n",
        "history = EMF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy2_IUhG-OAA"
      },
      "source": [
        "# Ratings prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "M5FpA7T3uA2v",
        "outputId": "c74279a9-c591-4b68-bbd5-fa14cb85761d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    itemid  predictions                                              title  \\\n",
              "0     3460     4.364036               Hillbillys in a Haunted House (1967)   \n",
              "1      701     4.324177                                       Daens (1992)   \n",
              "2     3057     4.307404                            Where's Marlowe? (1999)   \n",
              "3     2214     4.304979                            Number Seventeen (1932)   \n",
              "4     1145     4.299559                                  Snowriders (1996)   \n",
              "5     2258     4.292125                              Master Ninja I (1984)   \n",
              "6     3353     4.281912                         Closer You Get, The (2000)   \n",
              "7      868     4.278937                          Death in Brunswick (1991)   \n",
              "8      826     4.269901                                   Diebinnen (1995)   \n",
              "9     3305     4.266769                                   Bluebeard (1944)   \n",
              "10    2619     4.265997                                     Mascara (1999)   \n",
              "11     763     4.264092  Last of the High Kings, The (a.k.a. Summer Fli...   \n",
              "12    1852     4.262517                              Love Walked In (1998)   \n",
              "13     642     4.260353                                       Roula (1995)   \n",
              "14     682     4.258829         Tigrero: A Film That Was Never Made (1994)   \n",
              "15     792     4.253339                     Hungarian Fairy Tale, A (1987)   \n",
              "16    1316     4.252915                                        Anna (1996)   \n",
              "17    3228     4.245526                              Wirey Spindell (1999)   \n",
              "18     853     4.240745                                       Dingo (1992)   \n",
              "19    3172     4.238188                            Ulysses (Ulisse) (1954)   \n",
              "20    2254     4.238008                                     Choices (1981)   \n",
              "21    2503     4.234547                            Apple, The (Sib) (1998)   \n",
              "22    2905     4.224974                                     Sanjuro (1962)   \n",
              "23     744     4.224278                         Brothers in Trouble (1995)   \n",
              "24     757     4.224226                               Ashes of Time (1994)   \n",
              "25     858     4.223665                              Godfather, The (1972)   \n",
              "26     789     4.220788      I, Worst of All (Yo, la peor de todas) (1990)   \n",
              "27    3748     4.216508                                  Match, The (1999)   \n",
              "28     790     4.216455                     An Unforgettable Summer (1994)   \n",
              "29     745     4.215986                              Close Shave, A (1995)   \n",
              "\n",
              "                       genres  \n",
              "0                      Comedy  \n",
              "1                       Drama  \n",
              "2                      Comedy  \n",
              "3                    Thriller  \n",
              "4                 Documentary  \n",
              "5                      Action  \n",
              "6              Comedy|Romance  \n",
              "7                      Comedy  \n",
              "8                       Drama  \n",
              "9            Film-Noir|Horror  \n",
              "10                      Drama  \n",
              "11                      Drama  \n",
              "12             Drama|Thriller  \n",
              "13                      Drama  \n",
              "14          Documentary|Drama  \n",
              "15                    Fantasy  \n",
              "16                      Drama  \n",
              "17                     Comedy  \n",
              "18                      Drama  \n",
              "19                  Adventure  \n",
              "20                      Drama  \n",
              "21                      Drama  \n",
              "22           Action|Adventure  \n",
              "23                      Drama  \n",
              "24                      Drama  \n",
              "25         Action|Crime|Drama  \n",
              "26                      Drama  \n",
              "27             Comedy|Romance  \n",
              "28                      Drama  \n",
              "29  Animation|Comedy|Thriller  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d75564d0-cc69-4685-a379-09ced6b2f6e4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>itemid</th>\n",
              "      <th>predictions</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3460</td>\n",
              "      <td>4.364036</td>\n",
              "      <td>Hillbillys in a Haunted House (1967)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>701</td>\n",
              "      <td>4.324177</td>\n",
              "      <td>Daens (1992)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3057</td>\n",
              "      <td>4.307404</td>\n",
              "      <td>Where's Marlowe? (1999)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2214</td>\n",
              "      <td>4.304979</td>\n",
              "      <td>Number Seventeen (1932)</td>\n",
              "      <td>Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1145</td>\n",
              "      <td>4.299559</td>\n",
              "      <td>Snowriders (1996)</td>\n",
              "      <td>Documentary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2258</td>\n",
              "      <td>4.292125</td>\n",
              "      <td>Master Ninja I (1984)</td>\n",
              "      <td>Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3353</td>\n",
              "      <td>4.281912</td>\n",
              "      <td>Closer You Get, The (2000)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>868</td>\n",
              "      <td>4.278937</td>\n",
              "      <td>Death in Brunswick (1991)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>826</td>\n",
              "      <td>4.269901</td>\n",
              "      <td>Diebinnen (1995)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3305</td>\n",
              "      <td>4.266769</td>\n",
              "      <td>Bluebeard (1944)</td>\n",
              "      <td>Film-Noir|Horror</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2619</td>\n",
              "      <td>4.265997</td>\n",
              "      <td>Mascara (1999)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>763</td>\n",
              "      <td>4.264092</td>\n",
              "      <td>Last of the High Kings, The (a.k.a. Summer Fli...</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1852</td>\n",
              "      <td>4.262517</td>\n",
              "      <td>Love Walked In (1998)</td>\n",
              "      <td>Drama|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>642</td>\n",
              "      <td>4.260353</td>\n",
              "      <td>Roula (1995)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>682</td>\n",
              "      <td>4.258829</td>\n",
              "      <td>Tigrero: A Film That Was Never Made (1994)</td>\n",
              "      <td>Documentary|Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>792</td>\n",
              "      <td>4.253339</td>\n",
              "      <td>Hungarian Fairy Tale, A (1987)</td>\n",
              "      <td>Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1316</td>\n",
              "      <td>4.252915</td>\n",
              "      <td>Anna (1996)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3228</td>\n",
              "      <td>4.245526</td>\n",
              "      <td>Wirey Spindell (1999)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>853</td>\n",
              "      <td>4.240745</td>\n",
              "      <td>Dingo (1992)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3172</td>\n",
              "      <td>4.238188</td>\n",
              "      <td>Ulysses (Ulisse) (1954)</td>\n",
              "      <td>Adventure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2254</td>\n",
              "      <td>4.238008</td>\n",
              "      <td>Choices (1981)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2503</td>\n",
              "      <td>4.234547</td>\n",
              "      <td>Apple, The (Sib) (1998)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2905</td>\n",
              "      <td>4.224974</td>\n",
              "      <td>Sanjuro (1962)</td>\n",
              "      <td>Action|Adventure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>744</td>\n",
              "      <td>4.224278</td>\n",
              "      <td>Brothers in Trouble (1995)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>757</td>\n",
              "      <td>4.224226</td>\n",
              "      <td>Ashes of Time (1994)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>858</td>\n",
              "      <td>4.223665</td>\n",
              "      <td>Godfather, The (1972)</td>\n",
              "      <td>Action|Crime|Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>789</td>\n",
              "      <td>4.220788</td>\n",
              "      <td>I, Worst of All (Yo, la peor de todas) (1990)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3748</td>\n",
              "      <td>4.216508</td>\n",
              "      <td>Match, The (1999)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>790</td>\n",
              "      <td>4.216455</td>\n",
              "      <td>An Unforgettable Summer (1994)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>745</td>\n",
              "      <td>4.215986</td>\n",
              "      <td>Close Shave, A (1995)</td>\n",
              "      <td>Animation|Comedy|Thriller</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d75564d0-cc69-4685-a379-09ced6b2f6e4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d75564d0-cc69-4685-a379-09ced6b2f6e4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d75564d0-cc69-4685-a379-09ced6b2f6e4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# get list of top N items with their corresponding predicted ratings\n",
        "userid = 42\n",
        "recommended_items, predictions = EMF.recommend(userid=userid)\n",
        "\n",
        "# find corresponding movie titles\n",
        "top_N = list(zip(recommended_items,predictions))\n",
        "top_N = pd.DataFrame(top_N, columns=['itemid','predictions'])\n",
        "top_N.predictions = top_N.predictions + ratings.loc[ratings.userid==userid].rating_mean.values[0]\n",
        "List = pd.merge(top_N, movies, on='itemid', how='inner')\n",
        "\n",
        "# show the list\n",
        "List"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPeVMap_wu2T"
      },
      "source": [
        "**Note**: The recommendation list may content items already purchased by the user. This is just an illustration of how to implement matrix factorization recommender system. You can optimize the recommended list and return the top rated items that the user has not already purchased."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poBQ9Rsn-OAC"
      },
      "source": [
        "## Putting all together\n",
        "\n",
        "This repository covers the following algorithms for collaborative filtering\n",
        "\n",
        "1. User-based CF\n",
        "2. Item-based CF\n",
        "3. Singular Value Decomposition (SVD)\n",
        "4. Matrix Factorization (MF)\n",
        "5. Non-negative Matrix Factorization (NMF)\n",
        "6. Explainable Matrix Factorization (EMF)\n",
        "\n",
        "In the [next notebook](https://github.com/nzhinusoftcm/review-on-collaborative-filtering/blob/master/8.Performances_measure.ipynb), we present performances comparison of all these models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-jjxDhex5Gs"
      },
      "source": [
        "## Reference\n",
        "\n",
        "1. Yehuda Koren et al. (2009). <a href='https://ieeexplore.ieee.org/document/5197422'>Matrix Factorization Techniques for Recommender Systems</a>\n",
        "2. Abdollahi and Nasraoui (2016). [Explainable Matrix Factorization for Collaborative Filtering](https://www.researchgate.net/publication/301616080_Explainable_Matrix_Factorization_for_Collaborative_Filtering)\n",
        "3. Abdollahi and Nasraoui (2017). [Using Explainability for Constrained Matrix Factorization](https://dl.acm.org/doi/abs/10.1145/3109859.3109913)\n",
        "4. Shuo Wang et al, (2018). [Explainable Matrix Factorization with Constraints on Neighborhood in the Latent Space](https://dl.acm.org/doi/abs/10.1145/3109859.3109913)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jV3Jj17ox_UR"
      },
      "source": [
        "## Author\n",
        "\n",
        "[Carmel WENGA](https://www.linkedin.com/in/carmel-wenga-871876178/), <br>\n",
        "PhD student at Université de la Polynésie Française, <br> \n",
        "Applied Machine Learning Research Engineer, <br>\n",
        "[ShoppingList](https://shoppinglist.cm), NzhinuSoft."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
